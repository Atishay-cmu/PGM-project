Traceback (most recent call last):
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/mamba_708_categ_action_model/train.py", line 96, in <module>
    train_dreamer(exp, n_workers=args.n_workers)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/mamba_708_categ_action_model/train.py", line 23, in train_dreamer
    runner.run(exp.steps, exp.episodes)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/mamba_708_categ_action_model/agent/runners/DreamerRunner.py", line 51, in run
    self.learner.step(rollout)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/mamba_708_categ_action_model/agent/learners/DreamerLearner.py", line 133, in step
    self.train_agent(samples)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/mamba_708_categ_action_model/agent/learners/DreamerLearner.py", line 157, in train_agent
    actions, am_priors, am_posteriors, prev_policy_latents, av_actions, old_policy, imag_feat, imag_obs, returns = actor_rollout(samples['observation'],
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/mamba_708_categ_action_model/agent/optim/loss.py", line 62, in actor_rollout
    prev_policy_latent_state = actor.initial_state(post.stoch.shape[0], n_agents, device=obs.device) #method 1
  File "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'Actor' object has no attribute 'initial_state'