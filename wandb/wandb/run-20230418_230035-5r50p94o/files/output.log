Traceback (most recent call last):
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/train.py", line 96, in <module>
    train_dreamer(exp, n_workers=args.n_workers)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/train.py", line 23, in train_dreamer
    runner.run(exp.steps, exp.episodes)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/agent/runners/DreamerRunner.py", line 50, in run
    rollout, info = self.worker.run(self.learner.model, self.learner.action_model, self.learner.actor)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/agent/workers/DreamerWorker.py", line 96, in run
    actions, obs, fakes, av_actions = self._select_actions(state, model, action_model, actor)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/agent/workers/DreamerWorker.py", line 59, in _select_actions
    actions = self.controller.step(observations, av_action, nn_mask, model, action_model, actor)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/agent/controllers/DreamerController.py", line 88, in step
    policy_latent_state = self.select_latent_action(actor, observations, nn_mask) #method 1(policy consists of full transition model)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/agent/controllers/DreamerController.py", line 65, in select_latent_action
    actor_state = actor(obs.to(self.device), self.prev_policy_latent_state, nn_mask)
  File "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/networks/dreamer/action_model_rnns.py", line 102, in forward
    obs_embed = self.obs_encoder(obs)
  File "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/networks/dreamer/vae.py", line 28, in forward
    embed = F.relu(self.fc1(x))
  File "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)