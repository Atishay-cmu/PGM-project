Traceback (most recent call last):
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/train.py", line 96, in <module>
    train_dreamer(exp, n_workers=args.n_workers)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/train.py", line 23, in train_dreamer
    runner.run(exp.steps, exp.episodes)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/agent/runners/DreamerRunner.py", line 53, in run
    self.learner.step(rollout, cur_steps)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/agent/learners/DreamerLearner.py", line 126, in step
    self.train_model(samples1)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/agent/learners/DreamerLearner.py", line 139, in train_model
    self.model.train()
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/agent/optim/loss.py", line 21, in model_loss
    prior, post, deters = rollout_representation(model.representation, time_steps, embed, action, prev_state, last)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/networks/dreamer/rnns.py", line 108, in rollout_representation
    prior_states, posterior_states = representation_model(obs_embed[t], action[t], prev_states)
  File "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/networks/dreamer/rnns.py", line 89, in forward
    prior_states = self._transition_model(prev_actions, prev_states, mask)
  File "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/content/gdrive/.shortcut-targets-by-id/11LtEVzXkuxeMRaphtv1mvl4gTyvST0vX/pgmproj/networks/dreamer/rnns.py", line 60, in forward
    stoch_input = self._rnn_input_model(torch.cat([prev_actions, prev_states.stoch], dim=-1))
KeyboardInterrupt